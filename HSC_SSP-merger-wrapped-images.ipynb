{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from tf_fits.image import image_decode_fits\n",
    "from tf_fits.bintable import bintable_decode_fits\n",
    "\n",
    "from tensorflow_addons.image import rotate as tfa_image_rotate\n",
    "from math import pi\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if GPUs. If there are, some code to fix cuDNN bugs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train/'\n",
    "valid_path = './valid/'\n",
    "\n",
    "extn = '.fits'\n",
    "\n",
    "CLASS_NAMES = ['merger', 'nonmerger']\n",
    "NO_CLASS = len(CLASS_NAMES)\n",
    "\n",
    "train_images = glob.glob(train_path+'**/*'+extn)\n",
    "train_image_count = len(train_images)\n",
    "valid_images = glob.glob(valid_path+'**/*'+extn)\n",
    "valid_image_count = len(valid_images)\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "STEPS_PER_EPOCH = np.ceil(train_image_count/BATCH_SIZE).astype(int)\n",
    "STEPS_PER_VALID_EPOCH = 1\n",
    "\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "edge_cut = (128 - IMG_HEIGHT)//2\n",
    "CROP_FRAC = IMG_HEIGHT/(edge_cut+edge_cut+IMG_HEIGHT)\n",
    "\n",
    "print(train_image_count, STEPS_PER_EPOCH)\n",
    "print(valid_image_count, STEPS_PER_VALID_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_columns(table):\n",
    "    columns = tf.gather(table, [2,3,4,5,6,7,10,11,12,13,14,15,30,31,32])\n",
    "    return columns\n",
    "\n",
    "@tf.function\n",
    "def _normalise_condition(i, numcol, tf_MIN_MAX, table, new_table):\n",
    "    return tf.math.less(i, numcol)\n",
    "\n",
    "@tf.function\n",
    "def _normalise_body(i, numcol, tf_MIN_MAX, table, new_table):\n",
    "    \n",
    "    MIN = tf.gather_nd(tf_MIN_MAX, [i,0], name='MIN_slice')\n",
    "    MAX = tf.gather_nd(tf_MIN_MAX, [i,1], name='MAX_slice')\n",
    "    \n",
    "    column = tf.gather_nd(table, [i], name='table_gather')\n",
    "    column -= MIN\n",
    "    column /= tf.subtract(MAX, MIN)\n",
    "    new_table = new_table.write(i, column)\n",
    "    \n",
    "    i += 1\n",
    "    return i, numcol, tf_MIN_MAX, table, new_table\n",
    "\n",
    "@tf.function\n",
    "def normalise_columns(table):\n",
    "    tf_MIN_MAX = tf.constant([[0.0, 6.0],    #concentration\n",
    "                              [0.0, 3.0],    #deviation\n",
    "                              [0.0, 1.0],    #ellipticity_asymmetry\n",
    "                              [0.0, 1.0],    #ellipticity_centroid\n",
    "                              [0.0, 155.0],  #elongation_asymmetry\n",
    "                              [0.0, 155.0],  #elongation_centroid\n",
    "                              [0.0, 1.0],    #gini\n",
    "                              [-3.0, 3.0],   #gini_m20_bulge\n",
    "                              [-1.0, 1.0],   #gini_m20_merger\n",
    "                              [0.0, 1.0],    #intensity\n",
    "                              [-4.0, 0.0],   #m20\n",
    "                              [0.0, 1.0],    #multimode\n",
    "                              [0.0, 200.0],  #sersic_amplitude\n",
    "                              [-6.0, 3.0],   #sersic_ellip\n",
    "                              [0.0, 500.0]], #sersic_n\n",
    "                             dtype=tf.float32)\n",
    "    \n",
    "    numcol = tf.constant(15, name='numcol')    \n",
    "    i = tf.constant(0, name='i')\n",
    "    \n",
    "    new_table = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True, name='new_table')\n",
    "    \n",
    "    _, _, _, _, new_table = tf.while_loop(_normalise_condition, _normalise_body,\n",
    "                      [i, numcol, tf_MIN_MAX, table, new_table],\n",
    "                      shape_invariants=[i.get_shape(),\n",
    "                                        numcol.get_shape(),\n",
    "                                        tf_MIN_MAX.get_shape(),\n",
    "                                        table.get_shape(),\n",
    "                                        tf.TensorShape(None)])\n",
    "    \n",
    "    new_table = new_table.stack()\n",
    "    new_table = tf.reshape(new_table, (15,))\n",
    "\n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == CLASS_NAMES\n",
    "\n",
    "#@tf.function\n",
    "def decode_image(byte_data):\n",
    "    #Get the image from the byte string\n",
    "    img = image_decode_fits(byte_data, 0) \n",
    "    img = tf.reshape(img, (128,128,1))\n",
    "    return img\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    byte_data = tf.io.read_file(file_path)\n",
    "    img = decode_image(byte_data)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "g = tf.random.Generator.from_seed(1)#int(time()))\n",
    "\n",
    "#@tf.function\n",
    "def augment_img(img, label):\n",
    "    img = tf.image.rot90(img, k=g.uniform([], 0, 4, dtype=tf.int32))\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "#@tf.function\n",
    "def crop_img(img, label):\n",
    "    img = tf.slice(img, [edge_cut,edge_cut,0], [IMG_HEIGHT,IMG_HEIGHT,1])\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def prepare_dataset(ds, batch_size, shuffle_buffer_size=1000, training=False):\n",
    "    #Load images and labels\n",
    "    ds = ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    #cache result\n",
    "    ds = ds.cache()\n",
    "    #shuffle images\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    \n",
    "    #Augment Image\n",
    "    if training:\n",
    "        ds = ds.map(augment_img, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(crop_img, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    #Set batches and repeat forever\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.repeat()\n",
    "    \n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_ds = tf.data.Dataset.list_files(train_path+'*/*'+extn)\n",
    "train_ds = prepare_dataset(list_train_ds, BATCH_SIZE, train_image_count, True)\n",
    "\n",
    "list_valid_ds = tf.data.Dataset.list_files(valid_path+'*/*'+extn)\n",
    "valid_ds = prepare_dataset(list_valid_ds, valid_image_count, valid_image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train')\n",
    "i_batch, y_batch = next(iter(train_ds))\n",
    "print(i_batch.get_shape())\n",
    "print(y_batch.get_shape())\n",
    "print('valid')\n",
    "_ = next(iter(valid_ds))\n",
    "print('test load complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(image_model, self).__init__()\n",
    "        self.drop_rate = 0.2\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 6, strides=1, padding='same')\n",
    "        self.batn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.drop1 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(2, 2, padding='same')\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 5, strides=1, padding='same')\n",
    "        self.batn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.drop2 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(2, 2, padding='same')\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, 3, strides=1, padding='same')\n",
    "        self.batn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.drop3 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.conv4 = tf.keras.layers.Conv2D(128, 3, strides=1, padding='same')\n",
    "        self.batn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.drop4 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D(2, 2, padding='same')\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.fc1 = tf.keras.layers.Dense(2048)\n",
    "        self.batn5 = tf.keras.layers.BatchNormalization()\n",
    "        self.drop5 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.fc2 = tf.keras.layers.Dense(128)\n",
    "        self.batn6 = tf.keras.layers.BatchNormalization()\n",
    "        self.drop6 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        \n",
    "        x = self.conv1(inputs)\n",
    "        x = self.batn1(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.drop1(x, training=training)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.batn2(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.drop2(x, training=training)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batn3(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.drop3(x, training=training)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batn4(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.drop4(x, training=training)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.batn5(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.drop5(x, training=training)\n",
    "        x = self.fc2(x)\n",
    "        x = self.batn6(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.drop6(x, training=training)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class image_wrapper(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(image_wrapper, self).__init__()\n",
    "        self.y_out = tf.keras.layers.Dense(NO_CLASS, activation='softmax')\n",
    "        \n",
    "        self.image_model = image_model()\n",
    "        \n",
    "    def call(self, image, training=True):\n",
    "        x = self.image_model(image, training)\n",
    "        return self.y_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(images, labels):\n",
    "    '''labels shoule be one_hot'''\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(images)\n",
    "        loss = total_loss(labels, pred)\n",
    "        mean_loss = tf.reduce_mean(loss)\n",
    "\n",
    "    #Update gradients and optimize\n",
    "    grads = tape.gradient(mean_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    \n",
    "    #tf statistics tracking\n",
    "    train_loss(mean_loss)\n",
    "    train_accuracy(labels, pred)\n",
    "\n",
    "#@tf.function\n",
    "def val_step(images, labels):\n",
    "    '''labels should be one_hot'''\n",
    "    pred = model(images, training=False)\n",
    "    v_loss = total_loss(labels, pred)\n",
    "    mean_v_loss = tf.reduce_mean(v_loss)\n",
    "\n",
    "    #tf statistics tracking\n",
    "    val_loss(mean_v_loss)\n",
    "    val_accuracy(labels, pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = image_wrapper()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-6)   \n",
    "total_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = [0, 0, 100]\n",
    "t_los = []\n",
    "t_acc = []\n",
    "v_los = []\n",
    "v_acc = []\n",
    "run = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('To train on', train_image_count)\n",
    "print('To validate on', valid_image_count)\n",
    "\n",
    "template = 'Epoch {}\\nTrain Loss: {:.3g}, Train Accuracy: {:.3g}\\nValid Loss: {:.3g}, Valid Accuracy: {:.3g}'\n",
    "for epoch in range(0, EPOCHS):\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "    \n",
    "    #Train\n",
    "    print('Epoch', epoch+1+(EPOCHS*run), 'training')\n",
    "    for step in range(0, STEPS_PER_EPOCH):\n",
    "        i_batch, y_batch = next(iter(train_ds))\n",
    "        train_step(i_batch, y_batch)\n",
    "    \n",
    "    #Validate  \n",
    "    print('Epoch', epoch+1+(EPOCHS*run), 'validation')\n",
    "    y_val_all = None\n",
    "    val_pred = None\n",
    "    for step in range(0, STEPS_PER_VALID_EPOCH):\n",
    "        i_val, y_val = next(iter(valid_ds))\n",
    "        if y_val_all is None:\n",
    "            y_val_all = y_val\n",
    "        else:\n",
    "            y_val_all = np.vstack((y_val_all, y_val))\n",
    "        pred = val_step(i_val, y_val)\n",
    "        if val_pred is None:\n",
    "            val_pred = pred\n",
    "        else:\n",
    "            val_pred = np.vstack((val_pred, pred))\n",
    "    \n",
    "    print(template.format(epoch+1+(EPOCHS*run),\n",
    "                          train_loss.result(), train_accuracy.result(),\n",
    "                          val_loss.result(), val_accuracy.result()))\n",
    "    \n",
    "    t_los.append(train_loss.result())\n",
    "    t_acc.append(train_accuracy.result())\n",
    "    v_los.append(val_loss.result())\n",
    "    v_acc.append(val_accuracy.result())\n",
    "    \n",
    "    if val_loss.result() <= peak[2] or\\\n",
    "      (val_loss.result() == peak[2] and val_accuracy.result() >= peak[1]):\n",
    "        peak[0] = epoch+1+(EPOCHS*run)\n",
    "        peak[1] = val_accuracy.result()\n",
    "        peak[2] = val_loss.result()\n",
    "        model.image_model.save_weights('./saved_image_model_HSC_SSP-sex/checkpoint')\n",
    "        print('Saved')\n",
    "    \n",
    "    if val_accuracy.result() > 0.9:\n",
    "        y_val = np.argmax(y_val_all, axis=1)\n",
    "        y_out_val_agm = np.argmax(val_pred, axis=1)\n",
    "        for j in range(0, NO_CLASS):\n",
    "            testing = np.where(y_out_val_agm == j)\n",
    "            correct = np.where(np.logical_and(y_out_val_agm == j, y_val == j))\n",
    "            validating = np.where(y_val == j)\n",
    "     \n",
    "            if len(testing[0]) == 0:\n",
    "                cor_tes = 'inf'\n",
    "            elif len(correct[0]) == 0:\n",
    "                cor_tes = 0.0\n",
    "            else:\n",
    "                cor_tes = len(correct[0])/len(testing[0])\n",
    "                cor_tes = round(cor_tes, 3)\n",
    "    \n",
    "            if len(validating[0]) == 0:\n",
    "                cor_val = 'inf'\n",
    "            elif len(correct[0]) == 0:\n",
    "                cor_val = 0.0\n",
    "            else:\n",
    "                cor_val = len(correct[0])/len(validating[0])\n",
    "                cor_val = round(cor_val, 3)\n",
    "                \n",
    "            print('Val \\t Are', CLASS_NAMES[j], ' classed ', CLASS_NAMES[j], ':', cor_val, \n",
    "                  '(',len(correct[0]), 'of', len(validating[0]),')')\n",
    "            print('Val \\t Classed', CLASS_NAMES[j], ' are ', CLASS_NAMES[j], ':', cor_tes, \n",
    "                  '(',len(correct[0]), 'of', len(testing[0]),')')\n",
    "        \n",
    "    print()\n",
    "print('Peaks at Epoch', peak[0], 'with accuracy', np.round(peak[1],3), 'and loss', np.round(peak[2],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
